{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive', force_remount=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIUvSFU524gp",
        "outputId": "5777057f-942f-4c4f-9820-c58f1aa6ac66"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "kBLw2xlK09o3"
      },
      "outputs": [],
      "source": [
        "# ============================================================\n",
        "# FINAL TEAM TRANSLATION SCRIPT (DRIVE-SAFE + NO UNNEEDED API)\n",
        "# - Copy-only for TEACHER_LANGS (NO API calls)\n",
        "# - Translate only selected languages for THIS run\n",
        "# - Team sharding: 5 people + optional 2 sessions/person (2 notebooks/keys)\n",
        "# - High-quality prompts (similar to your old logic)\n",
        "# - Marker protection + validation (no new @/#/URLs)\n",
        "# - Batched translation (faster)\n",
        "# - DURABLE checkpointing to Google Drive (atomic write + fsync)\n",
        "# - Resume-safe (skips already translated row_ids in shard file)\n",
        "# ============================================================\n",
        "\n",
        "import os\n",
        "import re\n",
        "import json\n",
        "import time\n",
        "import hashlib\n",
        "from typing import List, Dict, Any, Tuple\n",
        "\n",
        "import pandas as pd\n",
        "from tqdm import tqdm\n",
        "\n",
        "from openai import OpenAI\n",
        "\n",
        "# =========================\n",
        "# 1) CONFIG\n",
        "# =========================\n",
        "\n",
        "# Input master (original)\n",
        "MASTER_IN = \"/content/drive/MyDrive/master_dataset.csv\"\n",
        "\n",
        "# Output directory for shards (each run writes its own file)\n",
        "OUT_DIR = \"/content/drive/MyDrive/translation_shards\"\n",
        "os.makedirs(OUT_DIR, exist_ok=True)\n",
        "\n",
        "# Output column name\n",
        "OUT_COL = \"text_en\"\n",
        "\n",
        "# Master columns\n",
        "TEXT_COL = \"text\"\n",
        "LANG_COL = \"lang\"\n",
        "SPLIT_COL = \"split\"\n",
        "\n",
        "# Translate only train by default (recommended)\n",
        "TRANSLATE_SPLITS = {\"train\"}  # change to {\"train\",\"dev\"} if you really want dev too\n",
        "\n",
        "# Teacher languages: copy-only (no API calls)\n",
        "TEACHER_LANGS = {\"eng\", \"spa\", \"deu\", \"rus\", \"tur\", \"pol\", \"arb\"}\n",
        "\n",
        "# Language names (for prompt)\n",
        "LANG_MAP = {\n",
        "    \"amh\": \"Amharic\", \"arb\": \"Arabic\", \"ben\": \"Bengali\", \"deu\": \"German\", \"eng\": \"English\",\n",
        "    \"fas\": \"Persian\", \"hau\": \"Hausa\", \"hin\": \"Hindi\", \"ita\": \"Italian\", \"khm\": \"Khmer\",\n",
        "    \"mya\": \"Burmese\", \"nep\": \"Nepali\", \"ori\": \"Odia\", \"pan\": \"Punjabi\", \"pol\": \"Polish\",\n",
        "    \"rus\": \"Russian\", \"spa\": \"Spanish\", \"swa\": \"Swahili\", \"tel\": \"Telugu\", \"tur\": \"Turkish\",\n",
        "    \"urd\": \"Urdu\", \"zho\": \"Chinese\"\n",
        "}\n",
        "\n",
        "# Team sharding\n",
        "N_PEOPLE = 5\n",
        "PERSON_ID = 0          # <-- each person sets 0..4\n",
        "\n",
        "# Two sessions per person:\n",
        "# Run the SAME script in 2 separate notebooks, each with a different API key:\n",
        "# - Notebook A: SESSION_ID=0\n",
        "# - Notebook B: SESSION_ID=1\n",
        "SESSION_ID = 1         # <-- set to 0 or 1 (or None if you don't want 2 sessions)\n",
        "N_SESSIONS_PER_PERSON = 2\n",
        "\n",
        "# Which languages THIS run should translate (non-teacher langs recommended)\n",
        "PERSON_LANGS = {\n",
        "  0: [\"urd\", \"hin\", \"hau\"],\n",
        "  1: [\"khm\", \"nep\", \"tel\"],\n",
        "  2: [\"ben\", \"amh\", \"ita\"],\n",
        "  3: [\"swa\", \"ori\", \"pan\"],\n",
        "  4: [\"zho\", \"mya\", \"fas\"],\n",
        "}\n",
        "LANGS_THIS_RUN = PERSON_LANGS[PERSON_ID]\n",
        "\n",
        "\n",
        "# Test mode\n",
        "TEST_MODE = False\n",
        "TEST_SAMPLES_PER_LANG = 5\n",
        "\n",
        "# OpenAI\n",
        "OPENAI_API_KEY = os.environ.get(\"OPENAI_API_KEY\", \"Hidden\")\n",
        "MODEL = \"gpt-4o-mini\"\n",
        "\n",
        "# Batching + saving\n",
        "BATCH_SIZE = 30      # 20–50 good. Use 10 for debugging saving\n",
        "SAVE_EVERY = 10      # save every N batches. Use 1 for debugging saving\n",
        "\n",
        "# Retry\n",
        "MAX_RETRIES = 4\n",
        "BASE_BACKOFF = 2.0"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 2) MARKER PROTECTION (same spirit as your old code)\n",
        "# =========================\n",
        "\n",
        "MARKER_PATTERNS = [\n",
        "    r'@\\w+',              # mentions\n",
        "    r'#\\w+',              # hashtags\n",
        "    r'https?://\\S+',      # URLs\n",
        "    r'www\\.\\S+',          # URLs\n",
        "]\n",
        "\n",
        "def extract_markers(text: str) -> set:\n",
        "    out = set()\n",
        "    for pat in MARKER_PATTERNS:\n",
        "        out.update(re.findall(pat, str(text)))\n",
        "    return out\n",
        "\n",
        "def stable_row_id(lang: str, text: str) -> str:\n",
        "    h = hashlib.sha256((str(lang) + \"||\" + str(text)).encode(\"utf-8\")).hexdigest()\n",
        "    return h[:16]\n",
        "\n",
        "def validate_translation(seed_text: str, translated: str) -> Tuple[bool, str]:\n",
        "    if not isinstance(translated, str) or len(translated.strip()) < 2:\n",
        "        return False, \"empty translation\"\n",
        "\n",
        "    # Marker constraint: translated must not introduce new markers\n",
        "    seed_markers = {m.lower() for m in extract_markers(seed_text)}\n",
        "    seed_markers.discard(\"@user\")  # allow @USER normalization\n",
        "    out_markers = {m.lower() for m in extract_markers(translated)}\n",
        "    out_markers.discard(\"@user\")\n",
        "\n",
        "    extra = out_markers - seed_markers\n",
        "    if extra:\n",
        "        return False, f\"introduced new marker(s): {list(extra)[:3]}\"\n",
        "\n",
        "    return True, \"ok\""
      ],
      "metadata": {
        "id": "MI2b-HFr1Mx-"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# =========================\n",
        "# 3) PROMPTS (high-quality, context-aware)\n",
        "# =========================\n",
        "\n",
        "SYSTEM_PROMPT = (\n",
        "    \"You are a professional human translator and localization expert.\\n\"\n",
        "    \"Translate social media text into natural, fluent English while preserving meaning, tone, and pragmatic intent.\\n\"\n",
        "    \"Use culturally appropriate equivalents; do NOT translate word-by-word if it harms meaning.\\n\"\n",
        "    \"Do NOT add explanations. Return ONLY valid JSON.\"\n",
        ")\n",
        "\n",
        "USER_TEMPLATE_SINGLE = \"\"\"Translate the following social media post into English.\n",
        "\n",
        "Source language: {source_lang_name} ({lang_code})\n",
        "\n",
        "TEXT:\n",
        "\\\"\\\"\\\"{text}\\\"\\\"\\\"\n",
        "\n",
        "CRITICAL REQUIREMENTS:\n",
        "- Preserve the original meaning, stance, and tone (including sarcasm, slang, dialect, irony).\n",
        "- Do NOT add new information.\n",
        "- Do NOT censor or soften content; translate faithfully.\n",
        "- Preserve ALL @mentions, #hashtags, and URLs EXACTLY as in the original (do not introduce new ones).\n",
        "- Keep formatting minimal and readable.\n",
        "\n",
        "Output JSON only:\n",
        "{{\n",
        "  \"translation\": \"...\"\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "# Batched version: returns list of translations aligned with inputs\n",
        "USER_TEMPLATE_BATCH = \"\"\"Translate the following social media posts into English.\n",
        "\n",
        "Source language: {source_lang_name} ({lang_code})\n",
        "\n",
        "CRITICAL REQUIREMENTS (apply to every item):\n",
        "- Preserve meaning, stance, and tone (sarcasm/slang/dialect/irony).\n",
        "- Do NOT add new information.\n",
        "- Do NOT censor/soften content; translate faithfully.\n",
        "- Preserve ALL @mentions, #hashtags, and URLs EXACTLY as in the original (do not introduce new ones).\n",
        "- Return EXACTLY one translation per input, same order.\n",
        "\n",
        "INPUTS (JSON array of strings):\n",
        "{inputs_json}\n",
        "\n",
        "Output JSON only:\n",
        "{{\n",
        "  \"translations\": [\"...\", \"...\"]\n",
        "}}\n",
        "\"\"\"\n",
        "\n",
        "# =========================\n",
        "# 4) SHARDING (deterministic)\n",
        "# =========================\n",
        "\n",
        "def assign_person(row_id_hex: str) -> int:\n",
        "    return int(row_id_hex, 16) % N_PEOPLE\n",
        "\n",
        "def assign_session(row_id_hex: str) -> int:\n",
        "    return int(row_id_hex, 16) % N_SESSIONS_PER_PERSON\n",
        "\n",
        "def chunk_list(xs: List[Any], n: int) -> List[List[Any]]:\n",
        "    return [xs[i:i+n] for i in range(0, len(xs), n)]\n",
        "\n",
        "# =========================\n",
        "# 5) DURABLE SAVE (atomic + fsync)\n",
        "# =========================\n",
        "\n",
        "def flush_shard(rows: List[Dict[str, Any]], path: str) -> None:\n",
        "    os.makedirs(os.path.dirname(path), exist_ok=True)\n",
        "    tmp = path + \".tmp\"\n",
        "    pd.DataFrame(rows).to_csv(tmp, index=False)\n",
        "\n",
        "    # force flush to disk\n",
        "    with open(tmp, \"rb\") as f:\n",
        "        os.fsync(f.fileno())\n",
        "\n",
        "    os.replace(tmp, path)\n",
        "\n",
        "# =========================\n",
        "# 6) OPENAI CALL (batch + retry + validation)\n",
        "# =========================\n",
        "\n",
        "def call_openai_translate_batch(\n",
        "    client: OpenAI,\n",
        "    lang_code: str,\n",
        "    seed_texts: List[str],\n",
        ") -> List[str]:\n",
        "    lang_name = LANG_MAP.get(lang_code, \"Unknown\")\n",
        "    user_prompt = USER_TEMPLATE_BATCH.format(\n",
        "        source_lang_name=lang_name,\n",
        "        lang_code=lang_code,\n",
        "        inputs_json=json.dumps(seed_texts, ensure_ascii=False)\n",
        "    )\n",
        "\n",
        "    last_err = None\n",
        "    for attempt in range(1, MAX_RETRIES + 1):\n",
        "        try:\n",
        "            resp = client.chat.completions.create(\n",
        "                model=MODEL,\n",
        "                messages=[\n",
        "                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                    {\"role\": \"user\", \"content\": user_prompt},\n",
        "                ],\n",
        "                response_format={\"type\": \"json_object\"},\n",
        "                temperature=0.2\n",
        "            )\n",
        "            data = json.loads(resp.choices[0].message.content)\n",
        "            outs = data.get(\"translations\", None)\n",
        "\n",
        "            if not isinstance(outs, list) or len(outs) != len(seed_texts):\n",
        "                raise ValueError(f\"Bad JSON: expected translations list of len {len(seed_texts)}\")\n",
        "\n",
        "            # Validate each translation (marker protection)\n",
        "            cleaned = []\n",
        "            for seed, tr in zip(seed_texts, outs):\n",
        "                ok, reason = validate_translation(seed, tr)\n",
        "                if not ok:\n",
        "                    raise ValueError(f\"Validation failed: {reason}\")\n",
        "                cleaned.append(str(tr).strip())\n",
        "\n",
        "            return cleaned\n",
        "\n",
        "        except Exception as e:\n",
        "            last_err = e\n",
        "            if attempt == MAX_RETRIES:\n",
        "                break\n",
        "            time.sleep(BASE_BACKOFF * (2 ** (attempt - 1)) + 0.25 * attempt)\n",
        "\n",
        "    raise RuntimeError(f\"Translation failed after retries: {last_err}\")\n",
        "\n",
        "def safe_read_csv(path: str) -> pd.DataFrame:\n",
        "    if (not os.path.exists(path)) or os.path.getsize(path) < 5:\n",
        "        # empty or non-existent -> treat as no previous progress\n",
        "        return pd.DataFrame()\n",
        "    return pd.read_csv(path)\n",
        "# =========================\n",
        "# 7) MAIN\n",
        "# =========================\n",
        "\n",
        "def main():\n",
        "    # 1) Load\n",
        "    df = pd.read_csv(MASTER_IN)\n",
        "\n",
        "    # 2) Ensure columns\n",
        "    if OUT_COL not in df.columns:\n",
        "        df[OUT_COL] = pd.NA\n",
        "\n",
        "    if \"row_id\" not in df.columns:\n",
        "        df[\"row_id\"] = [stable_row_id(l, t) for l, t in zip(df[LANG_COL], df[TEXT_COL])]\n",
        "\n",
        "    # 3) Copy-only teacher langs (NO API)\n",
        "    teacher_mask = df[LANG_COL].isin(TEACHER_LANGS)\n",
        "    df.loc[teacher_mask & df[OUT_COL].isna(), OUT_COL] = df.loc[teacher_mask & df[OUT_COL].isna(), TEXT_COL]\n",
        "\n",
        "    # 4) Work mask: chosen splits + langs + missing + not teacher\n",
        "    split_mask = df[SPLIT_COL].astype(str).isin(TRANSLATE_SPLITS)\n",
        "    lang_mask = df[LANG_COL].isin(LANGS_THIS_RUN)\n",
        "    need_mask = split_mask & lang_mask & (~teacher_mask) & (df[OUT_COL].isna())\n",
        "\n",
        "    # 5) Apply team sharding (ONLY if PERSON_ID / SESSION_ID are set)\n",
        "    idx = df.index[need_mask].tolist()\n",
        "\n",
        "    if SESSION_ID is not None:\n",
        "        idx = [i for i in idx if assign_session(str(df.at[i, \"row_id\"])) == SESSION_ID]\n",
        "\n",
        "\n",
        "    # 6) TEST_MODE sampling\n",
        "    if TEST_MODE:\n",
        "        sampled = []\n",
        "        for lg in LANGS_THIS_RUN:\n",
        "            candidates = [i for i in idx if df.at[i, LANG_COL] == lg]\n",
        "            sampled.extend(candidates[:TEST_SAMPLES_PER_LANG])\n",
        "        idx = sampled\n",
        "\n",
        "    # 7) Output path for shard (safe even when PERSON_ID/SESSION_ID is None)\n",
        "    person_tag = f\"person{PERSON_ID}\" if PERSON_ID is not None else \"personALL\"\n",
        "    sess_tag   = f\"S{SESSION_ID}\"     if SESSION_ID is not None else \"SALL\"\n",
        "\n",
        "    out_path = os.path.join(\n",
        "        OUT_DIR,\n",
        "        f\"shard_{person_tag}_{sess_tag}_\" + \"_\".join(LANGS_THIS_RUN) + \".csv\"\n",
        "    )\n",
        "    print(\"Shard output path:\", out_path)\n",
        "\n",
        "\n",
        "    # 8) Resume support (robust to empty/partial files)\n",
        "    done_row_ids = set()\n",
        "    shard_rows: List[Dict[str, Any]] = []\n",
        "\n",
        "    prev = safe_read_csv(out_path)\n",
        "    if not prev.empty:\n",
        "        # only accept if it actually has the expected columns\n",
        "        if \"row_id\" in prev.columns and OUT_COL in prev.columns:\n",
        "            done_row_ids = set(prev.loc[prev[OUT_COL].notna(), \"row_id\"].astype(str).tolist())\n",
        "        shard_rows = prev.to_dict(\"records\")\n",
        "        print(\"Resume: already translated in shard:\", len(done_row_ids))\n",
        "    else:\n",
        "        print(\"Resume: no valid previous shard (file missing or empty). Starting fresh.\")\n",
        "\n",
        "    idx = [i for i in idx if str(df.at[i, \"row_id\"]) not in done_row_ids]\n",
        "    print(\"Total master rows:\", len(df))\n",
        "    print(\"Teacher rows (copy-only) missing text_en:\", int((teacher_mask & df[OUT_COL].isna()).sum()))\n",
        "    print(\"Rows assigned to THIS run (after resume):\", len(idx))\n",
        "\n",
        "    if len(idx) == 0:\n",
        "        # still save shard (might contain previous work)\n",
        "        if shard_rows:\n",
        "            flush_shard(shard_rows, out_path)\n",
        "            print(f\"[FINAL SAVE] rows={len(shard_rows)} bytes={os.path.getsize(out_path)} mtime={time.ctime(os.path.getmtime(out_path))}\")\n",
        "        else:\n",
        "            print(\"[FINAL SAVE] skipped (no rows)\")\n",
        "\n",
        "\n",
        "    # 9) Group by language (batch per language)\n",
        "    groups: Dict[str, List[int]] = {}\n",
        "    for i in idx:\n",
        "        lg = str(df.at[i, LANG_COL])\n",
        "        groups.setdefault(lg, []).append(i)\n",
        "\n",
        "    # 10) Client\n",
        "    client = OpenAI(api_key=OPENAI_API_KEY)\n",
        "\n",
        "    # 11) Translate\n",
        "    total = sum(len(v) for v in groups.values())\n",
        "    pbar = tqdm(total=total, desc=\"Translating\")\n",
        "    batches_since_save = 0\n",
        "\n",
        "    failures = []\n",
        "    try:\n",
        "        for lg, rows in groups.items():\n",
        "            for chunk in chunk_list(rows, BATCH_SIZE):\n",
        "                seed_texts = [str(df.at[i, TEXT_COL]) for i in chunk]\n",
        "\n",
        "                try:\n",
        "                    outs = call_openai_translate_batch(client, lg, seed_texts)\n",
        "                except Exception as e:\n",
        "                    # fall back to single-item calls (debug + salvage)\n",
        "                    outs = []\n",
        "                    for one_i, one_seed in zip(chunk, seed_texts):\n",
        "                        try:\n",
        "                            # single prompt fallback\n",
        "                            lang_name = LANG_MAP.get(lg, \"Unknown\")\n",
        "                            user_prompt = USER_TEMPLATE_SINGLE.format(\n",
        "                                source_lang_name=lang_name,\n",
        "                                lang_code=lg,\n",
        "                                text=one_seed\n",
        "                            )\n",
        "                            resp = client.chat.completions.create(\n",
        "                                model=MODEL,\n",
        "                                messages=[\n",
        "                                    {\"role\": \"system\", \"content\": SYSTEM_PROMPT},\n",
        "                                    {\"role\": \"user\", \"content\": user_prompt},\n",
        "                                ],\n",
        "                                response_format={\"type\": \"json_object\"},\n",
        "                                temperature=0.2\n",
        "                            )\n",
        "                            data = json.loads(resp.choices[0].message.content)\n",
        "                            tr = data.get(\"translation\", \"\")\n",
        "                            ok, reason = validate_translation(one_seed, tr)\n",
        "                            if not ok:\n",
        "                                raise ValueError(reason)\n",
        "                            outs.append(str(tr).strip())\n",
        "                        except Exception as e2:\n",
        "                            failures.append({\n",
        "                                \"row_id\": str(df.at[one_i, \"row_id\"]),\n",
        "                                \"lang\": lg,\n",
        "                                \"error\": str(e2),\n",
        "                                \"seed_text\": one_seed[:500]\n",
        "                            })\n",
        "                            outs.append(None)\n",
        "\n",
        "                # write successes\n",
        "                for i, tr in zip(chunk, outs):\n",
        "                    if tr is None:\n",
        "                        continue\n",
        "                    df.at[i, OUT_COL] = tr\n",
        "                    shard_rows.append({\n",
        "                        \"row_id\": str(df.at[i, \"row_id\"]),\n",
        "                        LANG_COL: str(df.at[i, LANG_COL]),\n",
        "                        SPLIT_COL: str(df.at[i, SPLIT_COL]),\n",
        "                        TEXT_COL: str(df.at[i, TEXT_COL]),\n",
        "                        OUT_COL: tr\n",
        "                    })\n",
        "\n",
        "                pbar.update(len(chunk))\n",
        "                batches_since_save += 1\n",
        "\n",
        "                if batches_since_save >= SAVE_EVERY:\n",
        "                    if shard_rows:\n",
        "                        flush_shard(shard_rows, out_path)\n",
        "                        print(f\"[SAVED] rows={len(shard_rows)} bytes={os.path.getsize(out_path)} mtime={time.ctime(os.path.getmtime(out_path))}\")\n",
        "                    else:\n",
        "                        print(\"[SAVED] skipped (no rows yet)\")\n",
        "                    batches_since_save = 0\n",
        "\n",
        "\n",
        "        # final flush\n",
        "        flush_shard(shard_rows, out_path)\n",
        "        print(f\"[FINAL SAVE] rows={len(shard_rows)} bytes={os.path.getsize(out_path)} mtime={time.ctime(os.path.getmtime(out_path))}\")\n",
        "\n",
        "        # failures log\n",
        "        if failures:\n",
        "            fail_path = out_path.replace(\".csv\", \"_failures.jsonl\")\n",
        "            with open(fail_path, \"a\", encoding=\"utf-8\") as f:\n",
        "                for r in failures:\n",
        "                    f.write(json.dumps(r, ensure_ascii=False) + \"\\n\")\n",
        "            print(\"Failures logged to:\", fail_path, \"count=\", len(failures))\n",
        "\n",
        "    finally:\n",
        "        pbar.close()\n",
        "\n",
        "    # TEST_MODE preview\n",
        "    if TEST_MODE:\n",
        "        print(\"\\n=== TEST MODE PREVIEW ===\")\n",
        "        if shard_rows:\n",
        "            preview = pd.DataFrame(shard_rows).tail(10)\n",
        "            print(preview[[LANG_COL, TEXT_COL, OUT_COL]].to_string(index=False))\n",
        "        else:\n",
        "            print(\"(empty) No successful translations generated.\")\n",
        "\n",
        "    print(\"DONE. Shard saved:\", out_path)\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    main()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BTXKbfW51Wit",
        "outputId": "139f28ac-58a9-4fb7-9a2e-cf0d1b1230eb"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shard output path: /content/drive/MyDrive/translation_shards/shard_person0_S1_urd_hin_hau.csv\n",
            "Resume: no valid previous shard (file missing or empty). Starting fresh.\n",
            "Total master rows: 77368\n",
            "Teacher rows (copy-only) missing text_en: 0\n",
            "Rows assigned to THIS run (after resume): 4917\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:   6%|▌         | 300/4917 [05:39<1:36:01,  1.25s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=300 bytes=83439 mtime=Sun Jan  4 14:13:41 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  12%|█▏        | 600/4917 [15:32<1:35:12,  1.32s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=598 bytes=162417 mtime=Sun Jan  4 14:23:35 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  18%|█▊        | 900/4917 [20:20<1:17:36,  1.16s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=898 bytes=237402 mtime=Sun Jan  4 14:28:22 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  24%|██▍       | 1200/4917 [30:21<1:14:36,  1.20s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=1195 bytes=317445 mtime=Sun Jan  4 14:38:23 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  31%|███       | 1500/4917 [41:26<2:49:24,  2.97s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=1490 bytes=392749 mtime=Sun Jan  4 14:49:29 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  36%|███▋      | 1787/4917 [52:03<51:46,  1.01it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=1770 bytes=469484 mtime=Sun Jan  4 15:00:06 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  42%|████▏     | 2087/4917 [1:51:34<9:20:53, 11.89s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=1989 bytes=542680 mtime=Sun Jan  4 15:59:36 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  49%|████▊     | 2387/4917 [2:37:16<6:00:28,  8.55s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=2249 bytes=631600 mtime=Sun Jan  4 16:45:18 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  55%|█████▍    | 2687/4917 [3:03:35<2:22:30,  3.83s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=2539 bytes=892111 mtime=Sun Jan  4 17:11:37 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  61%|██████    | 2987/4917 [3:31:53<2:57:58,  5.53s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=2810 bytes=1051638 mtime=Sun Jan  4 17:39:55 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  66%|██████▋   | 3269/4917 [4:19:00<5:11:13, 11.33s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=3026 bytes=1121627 mtime=Sun Jan  4 18:27:02 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  73%|███████▎  | 3569/4917 [5:32:39<5:36:00, 14.96s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=3220 bytes=1182002 mtime=Sun Jan  4 19:40:42 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  79%|███████▊  | 3869/4917 [6:34:03<3:00:05, 10.31s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=3428 bytes=1248415 mtime=Sun Jan  4 20:42:05 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  85%|████████▍ | 4169/4917 [7:50:49<3:15:15, 15.66s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=3613 bytes=1304735 mtime=Sun Jan  4 21:58:52 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  91%|█████████ | 4469/4917 [8:58:52<1:49:11, 14.62s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=3807 bytes=1364950 mtime=Sun Jan  4 23:06:55 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating:  97%|█████████▋| 4769/4917 [10:00:05<29:32, 11.98s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[SAVED] rows=4024 bytes=1430868 mtime=Mon Jan  5 00:08:07 2026\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Translating: 100%|██████████| 4917/4917 [10:11:25<00:00,  7.46s/it]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[FINAL SAVE] rows=4165 bytes=1473784 mtime=Mon Jan  5 00:19:28 2026\n",
            "Failures logged to: /content/drive/MyDrive/translation_shards/shard_person0_S1_urd_hin_hau_failures.jsonl count= 752\n",
            "DONE. Shard saved: /content/drive/MyDrive/translation_shards/shard_person0_S1_urd_hin_hau.csv\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    }
  ]
}